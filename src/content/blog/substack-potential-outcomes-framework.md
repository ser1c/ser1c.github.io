---
title: "Potential Outcomes Framework"
description: "Causality Series"
author:
  - name: "Sabin Subedi"
    url: "https://sabinsubedi.substack.com"
date: "2024-07-16"
categories: ["Substack"]
draft: false
substackLink: "https://sabinsubedi.substack.com/p/potential-outcomes-framework"
---

<p></p><h3>Causality and Causal Inference</h3><p>Understanding causation has long been one of the central questions in economics. But it is important to understand that causality and causal inference are two different things. Causality defines the relationship between a cause and an effect. Simply, Causality is understanding if A causes B and how much does A cause B. It is a very simple question but one very difficult to answer. The concept of causality is central concept in science, philosophy, economics, and also everyday reasoning.</p><p>Causal inference is, however, about beliefs. When can we say that A caused B, when can we say that A did not cause B. The type of causality we are interested in is A causes B if we change the value of A, then B also changes without changing anything else (Ceteris Paribus)</p><p>Much of the earlier development looked into causal estimates from a modelling perspective. The biggest jump in this understanding was when <a href="https://www.cambridge.org/us/universitypress/subjects/mathematics/historical-mathematical-texts/theoria-motus-corporum-coelestium-sectionibus-conicis-solem-ambientium">Gauss derived the OLS estimator in 1809</a>. The evolution is well explained in the book <a href="https://www.jstor.org/stable/j.ctv1c29t27">Causal Inference: The Mixtape</a> by Scott Cunningham. For me, understanding the history behind my work is essential, so I will give you how we reached the potential outcomes framework and then see what it means and its impact.</p><h3>Emergence of Potential Outcome</h3><p>The first notion of potential outcomes can be traced back to <a href="https://www.jstor.org/stable/2245382">Neyman in 1923</a>.  I will simplify how the notion of potential outcome came from this. In his thought experiment, he divides a farm into &#8216;m&#8217; number of plots. And with him he has &#8216;v&#8217; number of different fertilizers. He wants to know what happens when each fertilizer is applied to every plot. But the problem here is that, in reality you can only apply one fertilizer to each plot. For simplicity, lets say we have plot A, B and C and two fertilizer 1 and 2. In his framework he considers the following:</p><ul><li><p>The yield of Plot A if given Fertilizer 1</p></li><li><p>The yield of Plot A if given Fertilizer 2</p></li><li><p>The yield of Plot B if given Fertilizer 1</p></li><li><p>The yield of Plot B if given Fertilizer 2</p></li><li><p>The yield of Plot C if given Fertilizer 1</p></li><li><p>The yield of Plot C if given Fertilizer 2</p></li></ul><p>Given the situation, these hypothetical yields for each plot under each fertilizer are a &#8216;potential outcome&#8217;. In this approach, the effect of Fertilizer 1 vs Fertilizer 2 on Plot A would be the difference between it&#8217;s yield in these two state. Since we can only observe one of these situations at a time, only one of the potential outcomes can be observed. This is also known as the &#8216;fundamental problem of causal inference&#8217;. Neyman then solves this issue with randomization, which will be our topic in the future. But the takeaway is that his contribution to potential outcomes helps lay the groundwork for estimating causal effects. And thanks to <a href="https://psycnet.apa.org/record/1975-06502-001">this paper by Donald Rubin</a>, it is now widely used in expressing the causal statements.</p><h3>Potential Outcome Framework</h3><p>In the potential outcome framework, the causal effect is the comparison between two different states of the world. In the previous example, the difference in effect of fertilizers 1 and 2 on plot A was the difference between these two states of the world. Let&#8217;s understand this better with the help of notations we use in the potential outcomes framework.<br><br>Let&#8217;s consider a new fertilizer on the market. We want to know its effect on yield. In this case, let's assume there was no fertilizer use before this. We are essentially comparing fertilizer to non-fertilizer yield. </p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://sabinsubedi.substack.com/leaderboard?&amp;utm_source=post&quot;,&quot;text&quot;:&quot;Refer a friend&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://sabinsubedi.substack.com/leaderboard?&amp;utm_source=post"><span>Refer a friend</span></a></p><p>Let&#8217;s define a treatment variable, D<sub>i</sub>, which is a binary variable that takes value 1 if plot <em>i</em> receives fertilizer and 0 if it does not receive fertilizer. Potential outcomes (in this case yeilds) are then defined as Y<sub>i</sub><sup>1 </sup>if uni <em>i</em> received the treatment (fertilizer) and as Y<sub>i</sub><sup>0</sup> if the unit did not receive treatment. One important thing that you can notice here is that both the outcomes have subscript <em>i</em>, meaning that it indicates two different states for same individual <em>i</em>. They are sometimes represented like Y<sub>i</sub>(0) and Y<sub>i</sub>(1). All of this can be represented as follows:</p><div class="latex-rendered" data-attrs="{&quot;persistentExpression&quot;:&quot;D_{i} =\\begin{cases} 1 \\text{ if received fertilizer} \\\\ 0 \\text{ if did not receive fertilizer} \\end{cases}&quot;,&quot;id&quot;:&quot;ZWSSREJRQI&quot;}" data-component-name="LatexBlockToDOM"></div><div class="latex-rendered" data-attrs="{&quot;persistentExpression&quot;:&quot;Y_{i}^j =\\begin{cases} j = 1 \\text{ yield if received treatment} \\\\ j = 0 \\text{ yield if did not receive treatment} \\end{cases}&quot;,&quot;id&quot;:&quot;KPKMUPRYZV&quot;}" data-component-name="LatexBlockToDOM"></div><p></p><p>The true causal effect of fertilizer on plot <em>i </em>is therefore given by:</p><div class="latex-rendered" data-attrs="{&quot;persistentExpression&quot;:&quot; \\delta_i = Y_i^1-Y_i^0&quot;,&quot;id&quot;:&quot;RQYDJKUQWA&quot;}" data-component-name="LatexBlockToDOM"></div><p>Here these outcomes are hypothetical states of the world, but in reality as I said we can only observe only one state. So, it is impossible to estimate the true causal effect using the equation above. We can identify the observed outcome based on this model by this simple equation.</p><div class="latex-rendered" data-attrs="{&quot;persistentExpression&quot;:&quot;Y_i = D_iY^1_i+(1-D_i)Y^0_i&quot;,&quot;id&quot;:&quot;EBDPYUPSMR&quot;}" data-component-name="LatexBlockToDOM"></div><p>This equation gives us a realized outcome for each of the plots i. It is impossible to observe both Y<sub>i</sub><sup>1</sup> and Y<sub>i</sub><sup>0</sup> for the same plot. This equation gives us a situation like the following, which I like to view as this makes the impossibility of observing both states clearer.</p><div class="latex-rendered" data-attrs="{&quot;persistentExpression&quot;:&quot;Y_i = \\begin{cases}\n          Y^1_i\\text{ if }D_i=1 \\\\\n          Y^0_i\\text{ if }D_i=0\n        \\end{cases}&quot;,&quot;id&quot;:&quot;WGGXRUSAUR&quot;}" data-component-name="LatexBlockToDOM"></div><p>So the bottom line is that, since we cannot observe two states at once, we have the problem of missing data. And we can also call causal inference simply a missing data problem.</p><p></p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://sabinsubedi.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">Please subscribe if you think this is helpful and want to see this type of content.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p></p><h3>Average Treatment Effects</h3><p>Last thing I want to leave with you today is that, in general we are not concerned with individual effects, rather we are concerned about the average treatment effect. In practicality, policies are aimed at groups of people, or groups of areas. In this case groups of fields. So, the average effect of fertilizer is called the average treatment effect. It can be expressed as following:</p><div class="latex-rendered" data-attrs="{&quot;persistentExpression&quot;:&quot;E[\\delta]=E[Y_1 | D=1] - E[Y_0| D=1]&quot;,&quot;id&quot;:&quot;IXVFPVTTIB&quot;}" data-component-name="LatexBlockToDOM"></div><p>And I suggest you to get used to such notation. <em>E</em> here means expectations, and in simple words, it is a mean. Here, the average treatment effect is the average effect of fertilizer on treated group minus the average effect of fertilizer on non-treated groups. Think about what the issue here it. How can there be an effect of fertilizer on non-treated groups? Feel free to answer in the comments or send me an email.<br><br>See you in next post!</p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://sabinsubedi.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://sabinsubedi.substack.com/subscribe?"><span>Subscribe now</span></a></p><p></p>

---

> This post was originally published on [Substack](https://sabinsubedi.substack.com/p/potential-outcomes-framework). If you enjoyed this content, consider [subscribing to my newsletter](https://sabinsubedi.substack.com) for regular updates.
